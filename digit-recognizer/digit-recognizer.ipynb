{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2146,
     "status": "ok",
     "timestamp": 1691157632159,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "mwZS0b_Ofn-x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from google.colab import drive\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1691157632160,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "AX2_MfpgzqUa"
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1691157632161,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "N78G2uqwTUgl"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    loss_hist = []\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    pred = model(x).view(len(x), -1)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch%50 == 0:\n",
    "        loss_val, current = loss.item(), (batch + 1) * len(x)\n",
    "        print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1691157632161,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "3DMXpz8lUoNR"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x).view(len(x), -1)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1925,
     "status": "ok",
     "timestamp": 1691157634080,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "DtBYyROkgG9w",
    "outputId": "ebec16f5-426e-4b1c-c399-b6429e403461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1691157634081,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "Y39n8zhClMxm"
   },
   "outputs": [],
   "source": [
    "dataroot = 'gdrive/MyDrive/Colab Notebooks/digit-recognizer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 2437,
     "status": "ok",
     "timestamp": 1691157636515,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "BY3rtNgpnFOP",
    "outputId": "4d9e411e-5fb3-44a6-bf9d-4e447b2d93fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-74b6cb57-77c5-45a0-87a2-4bceeec721d3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74b6cb57-77c5-45a0-87a2-4bceeec721d3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-1308909a-82ea-47f9-abbc-5fb160f43db4\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1308909a-82ea-47f9-abbc-5fb160f43db4')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-1308909a-82ea-47f9-abbc-5fb160f43db4 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-74b6cb57-77c5-45a0-87a2-4bceeec721d3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-74b6cb57-77c5-45a0-87a2-4bceeec721d3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataroot + 'train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1691157636517,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "gBeErEM0lyUY"
   },
   "outputs": [],
   "source": [
    "# train_df = df.sample(frac=0.9)\n",
    "# test_df = df[~df.index.isin(train_df.index)]\n",
    "train_df = df\n",
    "test_df = df.sample(frac=0.3)\n",
    "\n",
    "train_x = train_df.drop('label', axis=1)\n",
    "train_y = train_df['label']\n",
    "\n",
    "test_x = test_df.drop('label', axis=1)\n",
    "test_y = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1691157636796,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "-QnbNm1Cl8PL"
   },
   "outputs": [],
   "source": [
    "# transforming dataset to tensor type\n",
    "train_x = torch.FloatTensor(np.reshape(np.array(train_x), (-1, 1, 28, 28)))\n",
    "train_y = torch.LongTensor(np.array(train_y))\n",
    "\n",
    "test_x = torch.FloatTensor(np.reshape(np.array(test_x), (-1, 1, 28, 28)))\n",
    "test_y = torch.LongTensor(np.array(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1691157637089,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "2bUK9jqHowjK",
    "outputId": "7b58823e-adbd-4402-c30f-3f2505d22134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_x[0][0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1691157637090,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "5Fa76Ldkp2I4"
   },
   "outputs": [],
   "source": [
    "training_data = TensorDataset(train_x, train_y)\n",
    "test_data = TensorDataset(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1691157637090,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "6tRh656tsVtu"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1691157637090,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "030CcsdMsh-E",
    "outputId": "d7801ff7-574c-48b4-ddd2-079b27e9e79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = ('cuda' if torch.cuda.is_available()\n",
    "          else 'mps' if torch.backends.mps.is_available()\n",
    "          else 'cpu')\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1691157637091,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "rZ3REAxYsxJK"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(128, 10, 3, stride=3, padding=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2177,
     "status": "ok",
     "timestamp": 1691157639263,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "kFgS4FnItTBp"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1691157639264,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "Ml8VGsFCS6y8"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-2)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158010,
     "status": "ok",
     "timestamp": 1691157797271,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "SvOwvT-VTHA3",
    "outputId": "7bfc2922-78b2-4b1d-8348-348b078c4b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training loop\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.297260  [  128/42000]\n",
      "loss: 2.034376  [ 6528/42000]\n",
      "loss: 1.669813  [12928/42000]\n",
      "loss: 1.128746  [19328/42000]\n",
      "loss: 0.906016  [25728/42000]\n",
      "loss: 0.692586  [32128/42000]\n",
      "loss: 0.432561  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.466300 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.450079  [  128/42000]\n",
      "loss: 0.303632  [ 6528/42000]\n",
      "loss: 0.291227  [12928/42000]\n",
      "loss: 0.199364  [19328/42000]\n",
      "loss: 0.278147  [25728/42000]\n",
      "loss: 0.219913  [32128/42000]\n",
      "loss: 0.139872  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.239866 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.222291  [  128/42000]\n",
      "loss: 0.153076  [ 6528/42000]\n",
      "loss: 0.148742  [12928/42000]\n",
      "loss: 0.120190  [19328/42000]\n",
      "loss: 0.195423  [25728/42000]\n",
      "loss: 0.133836  [32128/42000]\n",
      "loss: 0.087449  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.162831 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.160175  [  128/42000]\n",
      "loss: 0.112251  [ 6528/42000]\n",
      "loss: 0.102627  [12928/42000]\n",
      "loss: 0.093088  [19328/42000]\n",
      "loss: 0.156867  [25728/42000]\n",
      "loss: 0.094324  [32128/42000]\n",
      "loss: 0.068390  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.130379 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.125898  [  128/42000]\n",
      "loss: 0.090530  [ 6528/42000]\n",
      "loss: 0.077930  [12928/42000]\n",
      "loss: 0.079387  [19328/42000]\n",
      "loss: 0.131648  [25728/42000]\n",
      "loss: 0.071339  [32128/42000]\n",
      "loss: 0.057070  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.114337 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.103596  [  128/42000]\n",
      "loss: 0.075737  [ 6528/42000]\n",
      "loss: 0.062564  [12928/42000]\n",
      "loss: 0.070664  [19328/42000]\n",
      "loss: 0.113497  [25728/42000]\n",
      "loss: 0.056552  [32128/42000]\n",
      "loss: 0.048682  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.104558 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.088125  [  128/42000]\n",
      "loss: 0.063865  [ 6528/42000]\n",
      "loss: 0.051898  [12928/42000]\n",
      "loss: 0.064407  [19328/42000]\n",
      "loss: 0.099553  [25728/42000]\n",
      "loss: 0.046437  [32128/42000]\n",
      "loss: 0.042248  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.096995 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.077176  [  128/42000]\n",
      "loss: 0.053835  [ 6528/42000]\n",
      "loss: 0.043937  [12928/42000]\n",
      "loss: 0.059628  [19328/42000]\n",
      "loss: 0.088295  [25728/42000]\n",
      "loss: 0.039243  [32128/42000]\n",
      "loss: 0.037333  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.089990 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.069193  [  128/42000]\n",
      "loss: 0.045456  [ 6528/42000]\n",
      "loss: 0.037764  [12928/42000]\n",
      "loss: 0.055727  [19328/42000]\n",
      "loss: 0.078971  [25728/42000]\n",
      "loss: 0.033956  [32128/42000]\n",
      "loss: 0.033529  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.083272 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.063157  [  128/42000]\n",
      "loss: 0.038583  [ 6528/42000]\n",
      "loss: 0.032851  [12928/42000]\n",
      "loss: 0.052347  [19328/42000]\n",
      "loss: 0.071160  [25728/42000]\n",
      "loss: 0.029939  [32128/42000]\n",
      "loss: 0.030495  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.076988 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.058416  [  128/42000]\n",
      "loss: 0.033000  [ 6528/42000]\n",
      "loss: 0.028872  [12928/42000]\n",
      "loss: 0.049310  [19328/42000]\n",
      "loss: 0.064570  [25728/42000]\n",
      "loss: 0.026779  [32128/42000]\n",
      "loss: 0.027992  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.071245 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.054545  [  128/42000]\n",
      "loss: 0.028482  [ 6528/42000]\n",
      "loss: 0.025607  [12928/42000]\n",
      "loss: 0.046543  [19328/42000]\n",
      "loss: 0.058951  [25728/42000]\n",
      "loss: 0.024208  [32128/42000]\n",
      "loss: 0.025862  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.066077 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.051270  [  128/42000]\n",
      "loss: 0.024833  [ 6528/42000]\n",
      "loss: 0.022897  [12928/42000]\n",
      "loss: 0.043993  [19328/42000]\n",
      "loss: 0.054095  [25728/42000]\n",
      "loss: 0.022054  [32128/42000]\n",
      "loss: 0.024011  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.061474 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.048411  [  128/42000]\n",
      "loss: 0.021886  [ 6528/42000]\n",
      "loss: 0.020625  [12928/42000]\n",
      "loss: 0.041616  [19328/42000]\n",
      "loss: 0.049846  [25728/42000]\n",
      "loss: 0.020207  [32128/42000]\n",
      "loss: 0.022379  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.057396 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.045850  [  128/42000]\n",
      "loss: 0.019501  [ 6528/42000]\n",
      "loss: 0.018706  [12928/42000]\n",
      "loss: 0.039381  [19328/42000]\n",
      "loss: 0.046091  [25728/42000]\n",
      "loss: 0.018598  [32128/42000]\n",
      "loss: 0.020925  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.053785 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.043506  [  128/42000]\n",
      "loss: 0.017558  [ 6528/42000]\n",
      "loss: 0.017078  [12928/42000]\n",
      "loss: 0.037272  [19328/42000]\n",
      "loss: 0.042751  [25728/42000]\n",
      "loss: 0.017186  [32128/42000]\n",
      "loss: 0.019624  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.050570 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.041322  [  128/42000]\n",
      "loss: 0.015965  [ 6528/42000]\n",
      "loss: 0.015694  [12928/42000]\n",
      "loss: 0.035279  [19328/42000]\n",
      "loss: 0.039768  [25728/42000]\n",
      "loss: 0.015939  [32128/42000]\n",
      "loss: 0.018452  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.047682 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.039263  [  128/42000]\n",
      "loss: 0.014648  [ 6528/42000]\n",
      "loss: 0.014514  [12928/42000]\n",
      "loss: 0.033399  [19328/42000]\n",
      "loss: 0.037098  [25728/42000]\n",
      "loss: 0.014837  [32128/42000]\n",
      "loss: 0.017393  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.045061 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.037305  [  128/42000]\n",
      "loss: 0.013549  [ 6528/42000]\n",
      "loss: 0.013503  [12928/42000]\n",
      "loss: 0.031630  [19328/42000]\n",
      "loss: 0.034705  [25728/42000]\n",
      "loss: 0.013859  [32128/42000]\n",
      "loss: 0.016432  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.042657 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.035432  [  128/42000]\n",
      "loss: 0.012625  [ 6528/42000]\n",
      "loss: 0.012624  [12928/42000]\n",
      "loss: 0.029970  [19328/42000]\n",
      "loss: 0.032562  [25728/42000]\n",
      "loss: 0.012989  [32128/42000]\n",
      "loss: 0.015558  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.040437 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.033639  [  128/42000]\n",
      "loss: 0.011841  [ 6528/42000]\n",
      "loss: 0.011843  [12928/42000]\n",
      "loss: 0.028416  [19328/42000]\n",
      "loss: 0.030645  [25728/42000]\n",
      "loss: 0.012211  [32128/42000]\n",
      "loss: 0.014760  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.038376 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.031923  [  128/42000]\n",
      "loss: 0.011169  [ 6528/42000]\n",
      "loss: 0.011137  [12928/42000]\n",
      "loss: 0.026965  [19328/42000]\n",
      "loss: 0.028933  [25728/42000]\n",
      "loss: 0.011511  [32128/42000]\n",
      "loss: 0.014031  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.036455 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.030284  [  128/42000]\n",
      "loss: 0.010590  [ 6528/42000]\n",
      "loss: 0.010488  [12928/42000]\n",
      "loss: 0.025613  [19328/42000]\n",
      "loss: 0.027405  [25728/42000]\n",
      "loss: 0.010876  [32128/42000]\n",
      "loss: 0.013364  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.034662 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.028725  [  128/42000]\n",
      "loss: 0.010087  [ 6528/42000]\n",
      "loss: 0.009887  [12928/42000]\n",
      "loss: 0.024355  [19328/42000]\n",
      "loss: 0.026044  [25728/42000]\n",
      "loss: 0.010295  [32128/42000]\n",
      "loss: 0.012752  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.032987 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.027245  [  128/42000]\n",
      "loss: 0.009646  [ 6528/42000]\n",
      "loss: 0.009327  [12928/42000]\n",
      "loss: 0.023186  [19328/42000]\n",
      "loss: 0.024832  [25728/42000]\n",
      "loss: 0.009759  [32128/42000]\n",
      "loss: 0.012190  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.031419 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.025843  [  128/42000]\n",
      "loss: 0.009257  [ 6528/42000]\n",
      "loss: 0.008804  [12928/42000]\n",
      "loss: 0.022101  [19328/42000]\n",
      "loss: 0.023755  [25728/42000]\n",
      "loss: 0.009261  [32128/42000]\n",
      "loss: 0.011672  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.029953 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.024520  [  128/42000]\n",
      "loss: 0.008911  [ 6528/42000]\n",
      "loss: 0.008315  [12928/42000]\n",
      "loss: 0.021094  [19328/42000]\n",
      "loss: 0.022796  [25728/42000]\n",
      "loss: 0.008795  [32128/42000]\n",
      "loss: 0.011196  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.028582 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.023272  [  128/42000]\n",
      "loss: 0.008601  [ 6528/42000]\n",
      "loss: 0.007860  [12928/42000]\n",
      "loss: 0.020159  [19328/42000]\n",
      "loss: 0.021941  [25728/42000]\n",
      "loss: 0.008357  [32128/42000]\n",
      "loss: 0.010756  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.027301 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.022098  [  128/42000]\n",
      "loss: 0.008321  [ 6528/42000]\n",
      "loss: 0.007438  [12928/42000]\n",
      "loss: 0.019290  [19328/42000]\n",
      "loss: 0.021176  [25728/42000]\n",
      "loss: 0.007943  [32128/42000]\n",
      "loss: 0.010350  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.026102 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.020997  [  128/42000]\n",
      "loss: 0.008066  [ 6528/42000]\n",
      "loss: 0.007047  [12928/42000]\n",
      "loss: 0.018480  [19328/42000]\n",
      "loss: 0.020487  [25728/42000]\n",
      "loss: 0.007553  [32128/42000]\n",
      "loss: 0.009973  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.024982 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.019964  [  128/42000]\n",
      "loss: 0.007832  [ 6528/42000]\n",
      "loss: 0.006688  [12928/42000]\n",
      "loss: 0.017723  [19328/42000]\n",
      "loss: 0.019861  [25728/42000]\n",
      "loss: 0.007183  [32128/42000]\n",
      "loss: 0.009623  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.023934 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.018999  [  128/42000]\n",
      "loss: 0.007614  [ 6528/42000]\n",
      "loss: 0.006358  [12928/42000]\n",
      "loss: 0.017013  [19328/42000]\n",
      "loss: 0.019287  [25728/42000]\n",
      "loss: 0.006834  [32128/42000]\n",
      "loss: 0.009296  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.022952 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.018098  [  128/42000]\n",
      "loss: 0.007411  [ 6528/42000]\n",
      "loss: 0.006056  [12928/42000]\n",
      "loss: 0.016346  [19328/42000]\n",
      "loss: 0.018754  [25728/42000]\n",
      "loss: 0.006504  [32128/42000]\n",
      "loss: 0.008991  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.022030 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.017259  [  128/42000]\n",
      "loss: 0.007218  [ 6528/42000]\n",
      "loss: 0.005781  [12928/42000]\n",
      "loss: 0.015716  [19328/42000]\n",
      "loss: 0.018254  [25728/42000]\n",
      "loss: 0.006195  [32128/42000]\n",
      "loss: 0.008705  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.021162 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.016479  [  128/42000]\n",
      "loss: 0.007034  [ 6528/42000]\n",
      "loss: 0.005530  [12928/42000]\n",
      "loss: 0.015119  [19328/42000]\n",
      "loss: 0.017777  [25728/42000]\n",
      "loss: 0.005905  [32128/42000]\n",
      "loss: 0.008436  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.020343 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.015755  [  128/42000]\n",
      "loss: 0.006858  [ 6528/42000]\n",
      "loss: 0.005301  [12928/42000]\n",
      "loss: 0.014552  [19328/42000]\n",
      "loss: 0.017319  [25728/42000]\n",
      "loss: 0.005635  [32128/42000]\n",
      "loss: 0.008182  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.019569 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.015085  [  128/42000]\n",
      "loss: 0.006688  [ 6528/42000]\n",
      "loss: 0.005091  [12928/42000]\n",
      "loss: 0.014012  [19328/42000]\n",
      "loss: 0.016873  [25728/42000]\n",
      "loss: 0.005384  [32128/42000]\n",
      "loss: 0.007942  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.018836 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.014464  [  128/42000]\n",
      "loss: 0.006522  [ 6528/42000]\n",
      "loss: 0.004899  [12928/42000]\n",
      "loss: 0.013496  [19328/42000]\n",
      "loss: 0.016437  [25728/42000]\n",
      "loss: 0.005152  [32128/42000]\n",
      "loss: 0.007715  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.018138 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.013891  [  128/42000]\n",
      "loss: 0.006360  [ 6528/42000]\n",
      "loss: 0.004723  [12928/42000]\n",
      "loss: 0.013003  [19328/42000]\n",
      "loss: 0.016007  [25728/42000]\n",
      "loss: 0.004937  [32128/42000]\n",
      "loss: 0.007499  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.017473 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.013362  [  128/42000]\n",
      "loss: 0.006201  [ 6528/42000]\n",
      "loss: 0.004560  [12928/42000]\n",
      "loss: 0.012531  [19328/42000]\n",
      "loss: 0.015581  [25728/42000]\n",
      "loss: 0.004738  [32128/42000]\n",
      "loss: 0.007294  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.016837 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.012874  [  128/42000]\n",
      "loss: 0.005671  [ 6528/42000]\n",
      "loss: 0.005937  [12928/42000]\n",
      "loss: 0.008099  [19328/42000]\n",
      "loss: 0.016989  [25728/42000]\n",
      "loss: 0.004290  [32128/42000]\n",
      "loss: 0.008242  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.010293 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.015731  [  128/42000]\n",
      "loss: 0.004657  [ 6528/42000]\n",
      "loss: 0.005557  [12928/42000]\n",
      "loss: 0.008245  [19328/42000]\n",
      "loss: 0.016815  [25728/42000]\n",
      "loss: 0.004258  [32128/42000]\n",
      "loss: 0.008639  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.010173 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.015703  [  128/42000]\n",
      "loss: 0.004640  [ 6528/42000]\n",
      "loss: 0.005529  [12928/42000]\n",
      "loss: 0.008277  [19328/42000]\n",
      "loss: 0.016714  [25728/42000]\n",
      "loss: 0.004266  [32128/42000]\n",
      "loss: 0.008768  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.010100 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.015579  [  128/42000]\n",
      "loss: 0.004632  [ 6528/42000]\n",
      "loss: 0.005533  [12928/42000]\n",
      "loss: 0.008268  [19328/42000]\n",
      "loss: 0.016594  [25728/42000]\n",
      "loss: 0.004283  [32128/42000]\n",
      "loss: 0.008812  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.010041 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.015469  [  128/42000]\n",
      "loss: 0.004616  [ 6528/42000]\n",
      "loss: 0.005543  [12928/42000]\n",
      "loss: 0.008247  [19328/42000]\n",
      "loss: 0.016465  [25728/42000]\n",
      "loss: 0.004298  [32128/42000]\n",
      "loss: 0.008817  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009987 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.015369  [  128/42000]\n",
      "loss: 0.004597  [ 6528/42000]\n",
      "loss: 0.005553  [12928/42000]\n",
      "loss: 0.008224  [19328/42000]\n",
      "loss: 0.016337  [25728/42000]\n",
      "loss: 0.004310  [32128/42000]\n",
      "loss: 0.008803  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009937 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.015272  [  128/42000]\n",
      "loss: 0.004576  [ 6528/42000]\n",
      "loss: 0.005562  [12928/42000]\n",
      "loss: 0.008201  [19328/42000]\n",
      "loss: 0.016215  [25728/42000]\n",
      "loss: 0.004319  [32128/42000]\n",
      "loss: 0.008776  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009889 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.015176  [  128/42000]\n",
      "loss: 0.004555  [ 6528/42000]\n",
      "loss: 0.005570  [12928/42000]\n",
      "loss: 0.008178  [19328/42000]\n",
      "loss: 0.016099  [25728/42000]\n",
      "loss: 0.004323  [32128/42000]\n",
      "loss: 0.008741  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009843 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.015080  [  128/42000]\n",
      "loss: 0.004534  [ 6528/42000]\n",
      "loss: 0.005575  [12928/42000]\n",
      "loss: 0.008155  [19328/42000]\n",
      "loss: 0.015990  [25728/42000]\n",
      "loss: 0.004325  [32128/42000]\n",
      "loss: 0.008703  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009798 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.014985  [  128/42000]\n",
      "loss: 0.004513  [ 6528/42000]\n",
      "loss: 0.005578  [12928/42000]\n",
      "loss: 0.008131  [19328/42000]\n",
      "loss: 0.015887  [25728/42000]\n",
      "loss: 0.004325  [32128/42000]\n",
      "loss: 0.008661  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009754 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.014890  [  128/42000]\n",
      "loss: 0.004492  [ 6528/42000]\n",
      "loss: 0.005580  [12928/42000]\n",
      "loss: 0.008108  [19328/42000]\n",
      "loss: 0.015790  [25728/42000]\n",
      "loss: 0.004323  [32128/42000]\n",
      "loss: 0.008618  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009711 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.014797  [  128/42000]\n",
      "loss: 0.004472  [ 6528/42000]\n",
      "loss: 0.005580  [12928/42000]\n",
      "loss: 0.008084  [19328/42000]\n",
      "loss: 0.015698  [25728/42000]\n",
      "loss: 0.004319  [32128/42000]\n",
      "loss: 0.008574  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009669 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.014705  [  128/42000]\n",
      "loss: 0.004453  [ 6528/42000]\n",
      "loss: 0.005578  [12928/42000]\n",
      "loss: 0.008060  [19328/42000]\n",
      "loss: 0.015609  [25728/42000]\n",
      "loss: 0.004315  [32128/42000]\n",
      "loss: 0.008529  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009628 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.014615  [  128/42000]\n",
      "loss: 0.004434  [ 6528/42000]\n",
      "loss: 0.005575  [12928/42000]\n",
      "loss: 0.008036  [19328/42000]\n",
      "loss: 0.015524  [25728/42000]\n",
      "loss: 0.004310  [32128/42000]\n",
      "loss: 0.008485  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009587 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.014526  [  128/42000]\n",
      "loss: 0.004415  [ 6528/42000]\n",
      "loss: 0.005571  [12928/42000]\n",
      "loss: 0.008011  [19328/42000]\n",
      "loss: 0.015441  [25728/42000]\n",
      "loss: 0.004304  [32128/42000]\n",
      "loss: 0.008440  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009547 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.014439  [  128/42000]\n",
      "loss: 0.004397  [ 6528/42000]\n",
      "loss: 0.005566  [12928/42000]\n",
      "loss: 0.007986  [19328/42000]\n",
      "loss: 0.015361  [25728/42000]\n",
      "loss: 0.004298  [32128/42000]\n",
      "loss: 0.008397  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009508 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.014353  [  128/42000]\n",
      "loss: 0.004379  [ 6528/42000]\n",
      "loss: 0.005560  [12928/42000]\n",
      "loss: 0.007960  [19328/42000]\n",
      "loss: 0.015282  [25728/42000]\n",
      "loss: 0.004291  [32128/42000]\n",
      "loss: 0.008354  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009469 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.014269  [  128/42000]\n",
      "loss: 0.004361  [ 6528/42000]\n",
      "loss: 0.005553  [12928/42000]\n",
      "loss: 0.007935  [19328/42000]\n",
      "loss: 0.015205  [25728/42000]\n",
      "loss: 0.004284  [32128/42000]\n",
      "loss: 0.008311  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009431 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.014187  [  128/42000]\n",
      "loss: 0.004344  [ 6528/42000]\n",
      "loss: 0.005546  [12928/42000]\n",
      "loss: 0.007909  [19328/42000]\n",
      "loss: 0.015129  [25728/42000]\n",
      "loss: 0.004277  [32128/42000]\n",
      "loss: 0.008269  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009393 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.014106  [  128/42000]\n",
      "loss: 0.004327  [ 6528/42000]\n",
      "loss: 0.005537  [12928/42000]\n",
      "loss: 0.007883  [19328/42000]\n",
      "loss: 0.015053  [25728/42000]\n",
      "loss: 0.004270  [32128/42000]\n",
      "loss: 0.008228  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009356 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.014027  [  128/42000]\n",
      "loss: 0.004311  [ 6528/42000]\n",
      "loss: 0.005528  [12928/42000]\n",
      "loss: 0.007857  [19328/42000]\n",
      "loss: 0.014979  [25728/42000]\n",
      "loss: 0.004262  [32128/42000]\n",
      "loss: 0.008188  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009319 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.013949  [  128/42000]\n",
      "loss: 0.004295  [ 6528/42000]\n",
      "loss: 0.005519  [12928/42000]\n",
      "loss: 0.007831  [19328/42000]\n",
      "loss: 0.014906  [25728/42000]\n",
      "loss: 0.004255  [32128/42000]\n",
      "loss: 0.008148  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009282 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.013873  [  128/42000]\n",
      "loss: 0.004279  [ 6528/42000]\n",
      "loss: 0.005509  [12928/42000]\n",
      "loss: 0.007804  [19328/42000]\n",
      "loss: 0.014833  [25728/42000]\n",
      "loss: 0.004247  [32128/42000]\n",
      "loss: 0.008109  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009246 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.013798  [  128/42000]\n",
      "loss: 0.004263  [ 6528/42000]\n",
      "loss: 0.005499  [12928/42000]\n",
      "loss: 0.007778  [19328/42000]\n",
      "loss: 0.014761  [25728/42000]\n",
      "loss: 0.004239  [32128/42000]\n",
      "loss: 0.008071  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009210 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.013724  [  128/42000]\n",
      "loss: 0.004248  [ 6528/42000]\n",
      "loss: 0.005488  [12928/42000]\n",
      "loss: 0.007751  [19328/42000]\n",
      "loss: 0.014689  [25728/42000]\n",
      "loss: 0.004231  [32128/42000]\n",
      "loss: 0.008034  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009175 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.013651  [  128/42000]\n",
      "loss: 0.004233  [ 6528/42000]\n",
      "loss: 0.005477  [12928/42000]\n",
      "loss: 0.007725  [19328/42000]\n",
      "loss: 0.014618  [25728/42000]\n",
      "loss: 0.004223  [32128/42000]\n",
      "loss: 0.007997  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009139 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.013579  [  128/42000]\n",
      "loss: 0.004218  [ 6528/42000]\n",
      "loss: 0.005465  [12928/42000]\n",
      "loss: 0.007698  [19328/42000]\n",
      "loss: 0.014548  [25728/42000]\n",
      "loss: 0.004215  [32128/42000]\n",
      "loss: 0.007960  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009104 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.013508  [  128/42000]\n",
      "loss: 0.004204  [ 6528/42000]\n",
      "loss: 0.005454  [12928/42000]\n",
      "loss: 0.007672  [19328/42000]\n",
      "loss: 0.014478  [25728/42000]\n",
      "loss: 0.004207  [32128/42000]\n",
      "loss: 0.007925  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009070 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.013439  [  128/42000]\n",
      "loss: 0.004189  [ 6528/42000]\n",
      "loss: 0.005442  [12928/42000]\n",
      "loss: 0.007645  [19328/42000]\n",
      "loss: 0.014408  [25728/42000]\n",
      "loss: 0.004199  [32128/42000]\n",
      "loss: 0.007890  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009035 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.013370  [  128/42000]\n",
      "loss: 0.004175  [ 6528/42000]\n",
      "loss: 0.005429  [12928/42000]\n",
      "loss: 0.007618  [19328/42000]\n",
      "loss: 0.014339  [25728/42000]\n",
      "loss: 0.004190  [32128/42000]\n",
      "loss: 0.007855  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.009001 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.013302  [  128/42000]\n",
      "loss: 0.004161  [ 6528/42000]\n",
      "loss: 0.005417  [12928/42000]\n",
      "loss: 0.007592  [19328/42000]\n",
      "loss: 0.014271  [25728/42000]\n",
      "loss: 0.004182  [32128/42000]\n",
      "loss: 0.007821  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008967 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.013235  [  128/42000]\n",
      "loss: 0.004147  [ 6528/42000]\n",
      "loss: 0.005404  [12928/42000]\n",
      "loss: 0.007565  [19328/42000]\n",
      "loss: 0.014203  [25728/42000]\n",
      "loss: 0.004173  [32128/42000]\n",
      "loss: 0.007788  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008934 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.013169  [  128/42000]\n",
      "loss: 0.004134  [ 6528/42000]\n",
      "loss: 0.005391  [12928/42000]\n",
      "loss: 0.007539  [19328/42000]\n",
      "loss: 0.014135  [25728/42000]\n",
      "loss: 0.004165  [32128/42000]\n",
      "loss: 0.007755  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008900 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.013104  [  128/42000]\n",
      "loss: 0.004120  [ 6528/42000]\n",
      "loss: 0.005379  [12928/42000]\n",
      "loss: 0.007512  [19328/42000]\n",
      "loss: 0.014068  [25728/42000]\n",
      "loss: 0.004156  [32128/42000]\n",
      "loss: 0.007723  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008867 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.013039  [  128/42000]\n",
      "loss: 0.004107  [ 6528/42000]\n",
      "loss: 0.005365  [12928/42000]\n",
      "loss: 0.007486  [19328/42000]\n",
      "loss: 0.014001  [25728/42000]\n",
      "loss: 0.004147  [32128/42000]\n",
      "loss: 0.007691  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008834 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.012976  [  128/42000]\n",
      "loss: 0.004094  [ 6528/42000]\n",
      "loss: 0.005352  [12928/42000]\n",
      "loss: 0.007460  [19328/42000]\n",
      "loss: 0.013935  [25728/42000]\n",
      "loss: 0.004139  [32128/42000]\n",
      "loss: 0.007659  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008802 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.012912  [  128/42000]\n",
      "loss: 0.004081  [ 6528/42000]\n",
      "loss: 0.005339  [12928/42000]\n",
      "loss: 0.007434  [19328/42000]\n",
      "loss: 0.013870  [25728/42000]\n",
      "loss: 0.004130  [32128/42000]\n",
      "loss: 0.007628  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008769 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.012850  [  128/42000]\n",
      "loss: 0.004068  [ 6528/42000]\n",
      "loss: 0.005325  [12928/42000]\n",
      "loss: 0.007407  [19328/42000]\n",
      "loss: 0.013805  [25728/42000]\n",
      "loss: 0.004121  [32128/42000]\n",
      "loss: 0.007598  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008737 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.012788  [  128/42000]\n",
      "loss: 0.004055  [ 6528/42000]\n",
      "loss: 0.005312  [12928/42000]\n",
      "loss: 0.007381  [19328/42000]\n",
      "loss: 0.013740  [25728/42000]\n",
      "loss: 0.004113  [32128/42000]\n",
      "loss: 0.007567  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008705 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.012727  [  128/42000]\n",
      "loss: 0.004043  [ 6528/42000]\n",
      "loss: 0.005298  [12928/42000]\n",
      "loss: 0.007356  [19328/42000]\n",
      "loss: 0.013676  [25728/42000]\n",
      "loss: 0.004104  [32128/42000]\n",
      "loss: 0.007537  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008673 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.012667  [  128/42000]\n",
      "loss: 0.004055  [ 6528/42000]\n",
      "loss: 0.005262  [12928/42000]\n",
      "loss: 0.006944  [19328/42000]\n",
      "loss: 0.013133  [25728/42000]\n",
      "loss: 0.003968  [32128/42000]\n",
      "loss: 0.007364  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008624 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.012660  [  128/42000]\n",
      "loss: 0.004029  [ 6528/42000]\n",
      "loss: 0.005310  [12928/42000]\n",
      "loss: 0.006959  [19328/42000]\n",
      "loss: 0.013068  [25728/42000]\n",
      "loss: 0.004022  [32128/42000]\n",
      "loss: 0.007397  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008616 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.012667  [  128/42000]\n",
      "loss: 0.004018  [ 6528/42000]\n",
      "loss: 0.005343  [12928/42000]\n",
      "loss: 0.006975  [19328/42000]\n",
      "loss: 0.013049  [25728/42000]\n",
      "loss: 0.004053  [32128/42000]\n",
      "loss: 0.007429  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008610 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.012675  [  128/42000]\n",
      "loss: 0.004014  [ 6528/42000]\n",
      "loss: 0.005364  [12928/42000]\n",
      "loss: 0.006988  [19328/42000]\n",
      "loss: 0.013049  [25728/42000]\n",
      "loss: 0.004070  [32128/42000]\n",
      "loss: 0.007460  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008607 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.012681  [  128/42000]\n",
      "loss: 0.004014  [ 6528/42000]\n",
      "loss: 0.005378  [12928/42000]\n",
      "loss: 0.006998  [19328/42000]\n",
      "loss: 0.013058  [25728/42000]\n",
      "loss: 0.004078  [32128/42000]\n",
      "loss: 0.007486  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008604 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.012684  [  128/42000]\n",
      "loss: 0.004016  [ 6528/42000]\n",
      "loss: 0.005386  [12928/42000]\n",
      "loss: 0.007006  [19328/42000]\n",
      "loss: 0.013069  [25728/42000]\n",
      "loss: 0.004082  [32128/42000]\n",
      "loss: 0.007510  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008602 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.012685  [  128/42000]\n",
      "loss: 0.004019  [ 6528/42000]\n",
      "loss: 0.005390  [12928/42000]\n",
      "loss: 0.007011  [19328/42000]\n",
      "loss: 0.013079  [25728/42000]\n",
      "loss: 0.004084  [32128/42000]\n",
      "loss: 0.007530  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008600 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.012683  [  128/42000]\n",
      "loss: 0.004022  [ 6528/42000]\n",
      "loss: 0.005392  [12928/42000]\n",
      "loss: 0.007014  [19328/42000]\n",
      "loss: 0.013088  [25728/42000]\n",
      "loss: 0.004084  [32128/42000]\n",
      "loss: 0.007548  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008598 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.012680  [  128/42000]\n",
      "loss: 0.004025  [ 6528/42000]\n",
      "loss: 0.005393  [12928/42000]\n",
      "loss: 0.007016  [19328/42000]\n",
      "loss: 0.013095  [25728/42000]\n",
      "loss: 0.004083  [32128/42000]\n",
      "loss: 0.007562  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008595 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.012676  [  128/42000]\n",
      "loss: 0.004028  [ 6528/42000]\n",
      "loss: 0.005392  [12928/42000]\n",
      "loss: 0.007017  [19328/42000]\n",
      "loss: 0.013101  [25728/42000]\n",
      "loss: 0.004081  [32128/42000]\n",
      "loss: 0.007575  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008593 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.012672  [  128/42000]\n",
      "loss: 0.004030  [ 6528/42000]\n",
      "loss: 0.005391  [12928/42000]\n",
      "loss: 0.007017  [19328/42000]\n",
      "loss: 0.013105  [25728/42000]\n",
      "loss: 0.004080  [32128/42000]\n",
      "loss: 0.007585  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008591 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.012666  [  128/42000]\n",
      "loss: 0.004032  [ 6528/42000]\n",
      "loss: 0.005389  [12928/42000]\n",
      "loss: 0.007016  [19328/42000]\n",
      "loss: 0.013108  [25728/42000]\n",
      "loss: 0.004078  [32128/42000]\n",
      "loss: 0.007594  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008589 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.012661  [  128/42000]\n",
      "loss: 0.004034  [ 6528/42000]\n",
      "loss: 0.005388  [12928/42000]\n",
      "loss: 0.007015  [19328/42000]\n",
      "loss: 0.013109  [25728/42000]\n",
      "loss: 0.004076  [32128/42000]\n",
      "loss: 0.007601  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008586 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.012655  [  128/42000]\n",
      "loss: 0.004036  [ 6528/42000]\n",
      "loss: 0.005385  [12928/42000]\n",
      "loss: 0.007013  [19328/42000]\n",
      "loss: 0.013110  [25728/42000]\n",
      "loss: 0.004073  [32128/42000]\n",
      "loss: 0.007607  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008584 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.012649  [  128/42000]\n",
      "loss: 0.004037  [ 6528/42000]\n",
      "loss: 0.005383  [12928/42000]\n",
      "loss: 0.007011  [19328/42000]\n",
      "loss: 0.013109  [25728/42000]\n",
      "loss: 0.004071  [32128/42000]\n",
      "loss: 0.007612  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008581 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.012643  [  128/42000]\n",
      "loss: 0.004038  [ 6528/42000]\n",
      "loss: 0.005381  [12928/42000]\n",
      "loss: 0.007008  [19328/42000]\n",
      "loss: 0.013108  [25728/42000]\n",
      "loss: 0.004070  [32128/42000]\n",
      "loss: 0.007615  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008578 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.012637  [  128/42000]\n",
      "loss: 0.004038  [ 6528/42000]\n",
      "loss: 0.005379  [12928/42000]\n",
      "loss: 0.007005  [19328/42000]\n",
      "loss: 0.013106  [25728/42000]\n",
      "loss: 0.004068  [32128/42000]\n",
      "loss: 0.007618  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008576 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.012631  [  128/42000]\n",
      "loss: 0.004038  [ 6528/42000]\n",
      "loss: 0.005377  [12928/42000]\n",
      "loss: 0.007003  [19328/42000]\n",
      "loss: 0.013103  [25728/42000]\n",
      "loss: 0.004066  [32128/42000]\n",
      "loss: 0.007620  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008573 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.012625  [  128/42000]\n",
      "loss: 0.004039  [ 6528/42000]\n",
      "loss: 0.005374  [12928/42000]\n",
      "loss: 0.007000  [19328/42000]\n",
      "loss: 0.013099  [25728/42000]\n",
      "loss: 0.004064  [32128/42000]\n",
      "loss: 0.007622  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008570 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.012619  [  128/42000]\n",
      "loss: 0.004039  [ 6528/42000]\n",
      "loss: 0.005372  [12928/42000]\n",
      "loss: 0.006997  [19328/42000]\n",
      "loss: 0.013096  [25728/42000]\n",
      "loss: 0.004062  [32128/42000]\n",
      "loss: 0.007623  [38528/42000]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.008567 \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "print('Start training loop')\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer, scheduler)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1691157797272,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "A0Uybm8ZdlDB"
   },
   "outputs": [],
   "source": [
    "def make_submission(x, model, y_label, sample, submission_path):\n",
    "    prediction = np.argmax(model(x).view(len(x), -1).cpu().detach().numpy(), axis=1)\n",
    "    submission = sample.copy()\n",
    "    submission[y_label] = prediction\n",
    "    submission.to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1816,
     "status": "ok",
     "timestamp": 1691157799063,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "hhIoxJguwfrV"
   },
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv(dataroot + 'test.csv')\n",
    "\n",
    "valid_x = torch.FloatTensor(np.reshape(np.array(valid_df), (-1, 1, 28, 28))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1691157799064,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "X4kERbICwtHx"
   },
   "outputs": [],
   "source": [
    "y_label = 'Label'\n",
    "sample = pd.read_csv(dataroot + 'sample_submission.csv')\n",
    "\n",
    "submission_path = dataroot + 'submission.csv'\n",
    "\n",
    "make_submission(valid_x, model, y_label, sample, submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1691157799064,
     "user": {
      "displayName": "Egor Khramtsov",
      "userId": "07896379739714639045"
     },
     "user_tz": -180
    },
    "id": "_Q0_btLaxQlV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPZ3nogq4le7JKYBu2DkSpM",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
